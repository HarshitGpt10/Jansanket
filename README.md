# ğŸ™Œ JanSanket â€“ Indian Regional Sign Language Translator ğŸ‡®ğŸ‡³

JanSanket is a real-time Indian Sign Language (ISL) interpretation platform that converts **static ISL alphabet gestures** into **multilingual text and speech output** across **9 Indian languages**.

Built with accessibility, inclusion, and scalability in mind, JanSanket aims to bridge communication gaps for the deaf and mute communitiesâ€”especially in rural and tribal areas where internet access is limited and regional language support is scarce.

---

## ğŸ¯ Problem Statement

India is home to **7+ million deaf or hard-of-hearing individuals**, many of whom rely on ISL. Yet:
- Most tools support only **ASL (American Sign Language)**.
- **No public platform supports Indian regional or tribal sign languages.**

JanSanket fills this critical void with an **real-time**, and **regionally inclusive** solution.

---

## ğŸ’¡ Features

- ğŸ–ï¸ Detects **A-Z static ISL gestures** using webcam.
- ğŸŒ Converts signs to **text** and **audio** in:
  - Hindi, English, Bengali, Tamil, Telugu, Malayalam, Marathi, Punjabi, Kokborok
- ğŸ”Š Text-to-speech support via Hugging Face models.
- ğŸ’» Lightweight and deployable on desktops or mobile devices.

---

## ğŸ› ï¸ Tech Stack

### ğŸ‘ï¸â€ğŸ—¨ï¸ Computer Vision
- [MediaPipe](https://google.github.io/mediapipe/) â€“ Real-time hand tracking (21-point hand landmarks)
- OpenCV â€“ Webcam integration and frame capture

### ğŸ§  Machine Learning
- CNN (Convolutional Neural Network) trained on Indian Sign Language datasets
- TensorFlow + Keras for model training
- TensorFlow Lite (TFLite) for edge deployment

### ğŸ—£ï¸ Natural Language & TTS
- Hugging Face ğŸ¤— Transformers
  - IndicTTS & Wav2Vec for speech synthesis in Indian languages

### ğŸŒ Web Interface
- HTML, TailwindCSS, JavaScript â€“ Frontend UI
- Python Flask â€“ Backend server and REST APIs

### ğŸ“¦ Tools & Frameworks
- Google Colab â€“ Model training
- GitHub Projects â€“ Agile planning & version control
- Figma â€“ UI mockups
- VSCode â€“ Development

---

## ğŸ§ª System Architecture

1. **Input**: Hand gesture via webcam
2. **Preprocessing**: Landmark extraction (MediaPipe)
3. **Classification**: CNN model infers gesture
4. **Translation**: Lookup maps gesture â†’ text in selected language
5. **Output**: Text displayed & spoken via TTS (offline)

---

## ğŸ“· Sample Interface

| Live Webcam Input | Translated Output |
|-------------------|--------------------|
| ![Camera](output.png) | 

---

## ğŸ”„ Future Roadmap

âœ… Current:
- Static gesture recognition (Aâ€“Z)
- Text/audio output in 9 Indian languages

ğŸš€ Planned:
- Dynamic gesture recognition (words/phrases)
- Reverse conversion (Text/Speech â†’ Sign)
- Android app using Flutter + TFLite
- Browser plugin / extension for **online meeting compatibility**
- School/NGO deployment in partnership with accessibility orgs
- Expanded dataset for regional signs (tribal/state-specific gestures)

---

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Team

A proud collaboration by 2nd-year CSE students from Bennett University:

- Harshit Gupta
- Devraj Singh Bhadoria
- Vaibhavi Rawat

### Special Thanks ğŸ™  
To our incredible mentor **Dr. Sanchali Das**, whose support and guidance empowered us to think inclusively and build meaningfully.

---

## ğŸ“„ Documentation

- ğŸ“˜ [Final Report PDF](Jansanket_Report.pdf)
- ğŸï¸ [PPT Presentation](Jansanket.pptx)
> ğŸ”’ *Core code/model files kept private for academic integrity.*

---

## ğŸ“¢ License

This repository is part of an academic capstone project and intended for educational/non-commercial use.

---

## ğŸ¤ Get Involved

Want to contribute or partner for real-world deployment?
Open an issue or drop us a message.

Letâ€™s make communication accessible â€” one sign at a time! ğŸ§â€â™‚ï¸ğŸ“²

---

### Tags:
`#SignLanguage` `#ISL` `#India` `#Accessibility` `#EdgeAI` `#DeepLearning` `#HuggingFace` `#TFLite` `#BennettUniversity` `#JanSanket` `#TechForGood`
